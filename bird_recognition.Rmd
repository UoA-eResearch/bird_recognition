---
title: "Bird Recognition"
output:
  html_notebook:
    toc: TRUE
    toc_float: TRUE
---

GitHub repo: https://github.com/UoA-eResearch/bird_recognition

## Load the necessary packages

```{r setup, warning=FALSE}
library(bioacoustics)
library(tuneR)
library(seewave)
library(dplyr)
library(tools)
library(randomForest)
library(stringr)
library(keras)
```

## Load the wave files. Separate out the metadata from the filename into columns. Render some spectrograms

```{r load}
files = list.files("wav_files_playback", "*.wav", full.names=TRUE)
files_without_extension = basename(file_path_sans_ext(files))
wavs = setNames(
  lapply(
    files,
    read_audio
  ),
  files_without_extension
)
metadata = data.frame(str_split_fixed(files_without_extension, "_", 3))
metadata = cbind(metadata, files_without_extension)
colnames(metadata) = c("birdid", "calltype", "idnumber", "filename")
head(metadata)
oscillo(wavs[[1]])
birds = unique(metadata$birdid)
filtered = filter(metadata, birdid == birds[1])
for (i in 1:nrow(filtered)) {
  audio = wavs[[filtered$filename[i]]]
  spectro(audio, main=filtered$filename[i])
}
```

Each calltype seems to have a unique spectrogram.

## Split dataset into train / test. The test dataset will contain one row for each combination of birdid / calltype

```{r split}
test = metadata %>% 
          group_by(birdid, calltype) %>% 
          filter(row_number()==1)
test
train = metadata %>% 
          group_by(birdid, calltype) %>% 
          filter(row_number()!=1)
train
```

## Train a random forest classifier based on Mel-frequency Cepstral Coefficients (MFCC)

```{r rf}
mels = sapply(wavs, melfcc, numcep = 20) # Calculate all MFCCs
head(mels[[1]]) # Result is a matrix of 20 coefficients across nrow time frames
image(mels[[1]])

trainMels = mels[train$filename] # Select the MFCCs corresponding to the training dataset
trainM = do.call(rbind, trainMels) # melfcc gives a matrix - rbind to cast from 3D to 2D across the whole training dataset
trainM.labels = rep(train$birdid, lapply(trainMels, function(x) dim(x)[1])) # Create birdid labels for each MFCC
rownames(trainM) = trainM.labels
head(trainM)

set.seed(1337)
rf = randomForest(trainM, trainM.labels, importance = FALSE, proximity = FALSE, replace = TRUE, ntree = 4000, mtry = 4)
rf
```
### Check accuracy of randomForest model

```{r rf-acc}
testMels = mels[test$filename]
testM = do.call(rbind, testMels)
testM.labels = rep(test$birdid, lapply(testMels, function(x) dim(x)[1]))
rownames(testM) = testM.labels
head(testM)

# Let's make predictions with our classifier on a test set
table = table(testM.labels, predict(rf, testM, type = "response"))
table

accuracy_pct = round(sum(diag(table)) / sum(table) * 100, 2)
print(paste("accuracy across whole dataset", accuracy_pct, "%"))

# To look at the predictions 
predict(rf, testM, type = "prob")

predictions = character(nrow(test))
for (i in 1:nrow(test)) {
  mel = testMels[[i]]
  prediction = names(which.max(colMeans(predict(rf, mel, type="prob"))))
  predictions[i] = prediction
}
testWithPredictions = data.frame(test, predictions)
testWithPredictions
correct_predictions = nrow(filter(testWithPredictions, birdid == predictions))
accuracy_pct = round(correct_predictions / nrow(test) * 100, 2)
print(paste(correct_predictions, "/", nrow(test), "wavs in the test dataset correctly identifed. Accuracy: ", accuracy_pct, "%"))
```


## Deep learning classification with the R interface to Keras based on MFCC

```{r keras, warning=FALSE}
mrows = max(sapply(mels, function(x) { nrow(x) }))
X_train = array(0, dim=c(length(trainMels), mrows, 20))

for (i in 1:length(trainMels)) {
  X_train[i,,] = apply(trainMels[[i]], 2, function(x) {approx(x,n=mrows)$y})
}

Y_train = to_categorical(as.integer(train$birdid) - 1)

X_test = array(0, dim=c(length(testMels), mrows, 20))
for (i in 1:length(testMels)) {
  X_test[i,,] = apply(testMels[[i]], 2, function(x) {approx(x,n=mrows)$y})
}

Y_test = to_categorical(as.integer(test$birdid) - 1)

batch = nrow(X_test)

# Build the sequential model
model = keras_model_sequential()
model %>%
  layer_lstm(units = 100,
    input_shape = dim(X_train)[-1],
    batch_size = batch,
    return_sequences = TRUE,
    stateful = TRUE) %>%
  layer_dropout(rate = 0.9) %>%
  layer_lstm(units = 50,
    return_sequences = FALSE,
    stateful = TRUE) %>%
  layer_dropout(rate = 0.5) %>%
  layer_dense(units = ncol(Y_train),  activation='softmax')

# Model compile
model %>% compile(loss = 'categorical_crossentropy',
                 optimizer = "adam",
                 metrics = "categorical_accuracy")

# Start learning
history = model %>% fit(X_train, Y_train, batch_size = batch, epochs = 200,
             validation_data = list(X_test, Y_test),
             verbose = 1)
```

```{r keras-plot}
plot(history)
```

### Check accuracy of keras model

```{r keras-acc}
# Score on the test set
model %>% evaluate(X_test, Y_test, batch_size = nrow(X_test))

predictions = character(nrow(test))
for (i in 1:nrow(test)) {
  mel = testMels[[i]]
  prediction = which.max(colMeans(predict_proba(model, mel)))
  prediction = levels(testM.labels)[prediction]
  predictions[i] = prediction
}
testWithPredictions = data.frame(test, predictions)
testWithPredictions
correct_predictions = nrow(filter(testWithPredictions, birdid == predictions))
accuracy_pct = round(correct_predictions / nrow(test) * 100, 2)
print(paste(correct_predictions, "/", nrow(test), "wavs in the test dataset correctly identifed. Accuracy: ", accuracy_pct, "%"))
```

randomForest did better.
