---
title: "Bird Recognition"
output:
  html_document:
    df_print: paged
    toc: yes
  html_notebook:
    toc: yes
    toc_float: yes
---

GitHub repo: https://github.com/UoA-eResearch/bird_recognition

## Load the necessary packages

```{r setup, warning=FALSE}
rm(list=ls(all=TRUE))
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning = FALSE)
knitr::opts_chunk$set(fig.width = 12, fig.height = 8, fig.align = 'center')

library(bioacoustics)
library(tuneR)
library(seewave)
library(dplyr)
library(tools)
library(ranger)
library(randomForest)
library(stringr)
library(keras)
library(ggplot2)
```

## Load the wave files. Separate out the metadata from the filename into columns. 

```{r load}
files = list.files("wav_files_playback", "*.wav", full.names=TRUE)
files_without_extension = basename(file_path_sans_ext(files))
wavs = setNames(
  lapply(
    files,
    read_audio
  ),
  files_without_extension
)
metadata = data.frame(str_split_fixed(files_without_extension, "_", 3))
metadata = cbind(metadata, files_without_extension)
colnames(metadata) = c("birdid", "calltype", "idnumber", "filename")
```

Render some spectrograms
```{r visualise spectro}
oscillo(wavs[[1]])
birds = unique(metadata$birdid)
filtered = filter(metadata, birdid == birds[1])
for (i in 1:nrow(filtered)) {
  audio = wavs[[filtered$filename[i]]]
  spectro(audio, main=filtered$filename[i])
}
```


```{r}
metadata %>%
  mutate(gender=substr(metadata$birdid,1,3)) %>% 
  ggplot(aes(gender, fill=gender)) +
  geom_bar() +
  facet_grid(.~metadata$calltype) 
```

Each calltype seems to have a unique spectrogram.

## Split dataset into train / test. The test dataset will contain one row for each combination of birdid / calltype

```{r split}
set.seed(1337)
test_row <- sample(1:3,1)
test_row
test <- metadata %>% 
          group_by(birdid, calltype) %>% 
          filter(row_number()==test_row) %>% 
          glimpse()
          
train <-  metadata %>% 
          group_by(birdid, calltype) %>% 
          filter(row_number()!=test_row) %>% 
          glimpse()
```
```{r}
metadata %>%
  group_by(birdid,calltype) %>% 
  mutate(isTrain=row_number()==test_row) %>% 
  ungroup() %>% 
  ggplot(aes(birdid,fill=isTrain)) +
    geom_bar(stat = "count") +
    facet_grid(calltype~.) +
    theme_minimal()
```

```{r rf}
mels = sapply(wavs, melfcc, numcep = 20) # Calculate all MFCCs
#head(mels[[1]]) # Result is a matrix of 20 coefficients across nrow time frames
#image(mels[[1]])
maxMels <- do.call(max,mels) # Calculate the max across the whole list of matrices to scale the predictor values between 0-1 later

trainMels = mels[train$filename] # Select the MFCCs corresponding to the training dataset
trainM = do.call(rbind, trainMels) # melfcc gives a matrix - rbind to cast from 3D to 2D across the whole training dataset
trainM.labels = rep(train$birdid, lapply(trainMels, function(x) dim(x)[1])) # Create birdid labels for each MFCC
rownames(trainM) = trainM.labels

testMels = mels[test$filename]
testM = do.call(rbind, testMels)
testM.labels = rep(test$birdid, lapply(testMels, function(x) dim(x)[1]))
rownames(testM) = testM.labels

```

Audio recordings have different lengths
```{r audio_len}
audio_len_train = sapply(trainMels, dim)
audio_len_test = sapply(testMels,dim)
boxplot(audio_len_train[1,])
hist(audio_len_train[1,], breaks = 50)
hist(audio_len_test[1,], breaks = 50)

#max(audio_len_test[1,])
# max(audio_len_train[1,])
# median(audio_len_test[1,])
# median(audio_len_train[1,])
#dim(trainMels[[1]])
#dim(trainMels[[3]])
#mean(audio_len_train[1,])
```

```{r}
### Adding more resolution to the spectrogram
# Define the function
addResolution <- function(matrixI) {
  test <- matrix(0,141,20)
  dimension <- dim(matrixI)
  test[1:dimension[1], 1:dimension[2]] <- matrixI
  test
}

timestepTake <- 20
# Only extract 20 first timesteps
extract20 <- function(matrixI) {
  test <- matrix(0,timestepTake,20)
  dimensionM <- dim(matrixI)
  timestepM <- min(timestepTake,dimensionM[1])
  test[1:timestepM, 1:dimensionM[2]] <- matrixI[1:timestepM, 1:dimensionM[2]]
  test
}

# Adding more elements to the matrices
trainMels_stretched <- lapply(trainMels, addResolution)
testMels_stretched <- lapply(testMels, addResolution)

# Only taking the first 20 timesteps othwerwise zero
trainMels_20 <- lapply(trainMels, extract20)
testMels_20 <- lapply(testMels, extract20)
```

```{r}
# Draw spectrograms
dim(trainMels_stretched[[1]]/maxMels)
image(trainMels_stretched[[1]]/maxMels)

dim(testMels_stretched[[10]])
image(testMels_stretched[[10]])

# Draw spectrograms
dim(trainMels_20[[1]]/maxMels)
image(trainMels_20[[1]]/maxMels)

dim(testMels_20[[10]])
image(testMels_20[[10]])
```
```{r}
# fem_distance <- test %>% 
#   filter(calltype=="distance") %>% 
#   filter(substr(birdid,1,3)=="fem") %>%
#   select(filename)
# 
# for (f in testMels_20[fem_distance$filename]) {
#   image(f)
# }
```

```{r}
# Flatten the matrices out
trainMels_stretched <- matrix(unlist(trainMels_stretched), ncol=(141*20), byrow=TRUE)
testMels_stretched <- matrix(unlist(testMels_stretched), ncol=(141*20), byrow=TRUE)

# Normalise
trainMels_stretched <- trainMels_stretched/maxMels
testMels_stretched <- testMels_stretched/maxMels

# Flatten the matrices out
trainMels_20 <- matrix(unlist(trainMels_20), ncol=(20*20), byrow=TRUE)
testMels_20 <- matrix(unlist(testMels_20), ncol=(20*20), byrow=TRUE)

# Normalise
trainMels_20 <- trainMels_20/maxMels
testMels_20 <- testMels_20/maxMels
```


## Using Random-Forest
```{r}
rf = randomForest(trainMels_20, train$birdid, xtest=testMels_20, ytest=test$birdid, importance = FALSE, proximity = FALSE, replace = TRUE, ntree = 4000, mtry = 20)
rf

round(sum(diag(rf$test$confusion)) / sum(rf$test$confusion) * 100, 2)
```

What about adding column means for each timestep?
```{r}
# Feature engineering
## Add column means or timestep means
colnames(trainMels_20) <- c(paste0("pix",1:400))
colnames(testMels_20) <- c(paste0("pix",1:400))

addColMeans <- function(matrixI) {
  mcol <- matrix(nrow=nrow(matrixI), ncol=timestepTake)
  for (i in 1:timestepTake) {
    mcol[,i] <- rowMeans(matrixI[,i+20*(0:19)])
  }
  colnames(mcol) <- c(paste0("m",1:20))
  results <- cbind(matrixI, mcol)
}

trainMels_20_M <- addColMeans(trainMels_20)
testMels_20_M <- addColMeans(testMels_20)
trainMels_20_M <- cbind(trainMels_20_M,train$birdid)
testMels_20_M <- cbind(testMels_20_M,test$birdid)

colnames(trainMels_20_M)[ncol(trainMels_20_M)] <- "birdid"
colnames(testMels_20_M)[ncol(testMels_20_M)] <- "birdid"

M_ranger <- ranger(dependent.variable.name = "birdid", data = trainMels_20_M, mtry = 20, classification = TRUE, num.trees = 4000)
M_ranger

t_M <- table(predict(M_ranger,testMels_20_M)$predictions, test$birdid)
round(sum(diag(t_M)) / sum(t_M) * 100, 2)
```
Adding timesteps means doesn't boost performance

## Deep learning classification with the R interface to Keras based on MFCC

```{r keras, warning=FALSE}
# Assigning input and output variables
X_train <-  trainMels_20
X_test <-  testMels_20
Y_train <-  to_categorical(as.integer(train$birdid) -1)
Y_test <-  to_categorical(as.integer(test$birdid) - 1)

# Build the sequential model
model = keras_model_sequential()
model %>%
  # Input shape layer = c(samples, rows, cols, channels)
  layer_reshape(input_shape=400,target_shape=c(20,20,1)) %>% 
  # First conv 2d layer with 128 neurons, kernel size of 8 x 8 and stride of 1 x 1
  layer_conv_2d(128, c(3,3), c(1,1), padding='same') %>%
  layer_batch_normalization() %>%
  layer_activation("relu") %>%
  layer_dropout(0.7) %>%
  # Second conv 2d layer with 256 neurons, kernel size of 5 x 5 and stride of 1 x 1
  layer_conv_2d(256, c(5,5), c(1,1), padding='same') %>%
  layer_batch_normalization() %>%
  layer_activation("relu") %>%
  layer_dropout(0.7) %>%
  # Third conv 2d layer with 128 neurons, kernel size of 3 x 3 and stride of 1 x 1
  layer_conv_2d(128, c(3,3), c(1,1), padding='same') %>%
  layer_batch_normalization() %>%
  layer_activation("relu") %>%
  layer_dropout(0.7) %>%
  # Average pooling layer
  layer_global_average_pooling_2d() %>%
  # Activation output layer with 2 classes
  layer_dense(units = ncol(Y_train),  activation='softmax')

# Model compile
model %>% compile(loss = 'categorical_crossentropy',
                 optimizer = "adam",
                 metrics = "categorical_accuracy")


# Add a callback to reduce the learning rate when reaching the plateau
reduce_lr <- callback_reduce_lr_on_plateau(monitor = 'loss', factor = 0.5,
                                           patience = 50, min_lr = 0.0001)
# Start learning
history = model %>% fit(X_train, Y_train, epochs = 50,
             validation_data = list(X_test, Y_test),
             verbose = 1, callbacks = reduce_lr)
```

```{r keras-plot}
plot(history)
```

### Check accuracy of the model

```{r rf-acc}
# Let's make predictions with our classifier on a test set
table = table(testM.labels, predict(rf, testM, type = "response"))
table

accuracy_pct = round(sum(diag(table)) / sum(table) * 100, 2)
print(paste("accuracy across whole dataset", accuracy_pct, "%"))

# To look at the predictions 
predict(rf, testM, type = "prob")

predictions = character(nrow(test))
for (i in 1:nrow(test)) {
  mel = testMels[[i]]
  prediction = names(which.max(colMeans(predict(rf, mel, type="prob"))))
  predictions[i] = prediction
}
testWithPredictions = data.frame(test, predictions)
testWithPredictions
correct_predictions = nrow(filter(testWithPredictions, birdid == predictions))
accuracy_pct = round(correct_predictions / nrow(test) * 100, 2)
print(paste(correct_predictions, "/", nrow(test), "wavs in the test dataset correctly identifed. Accuracy: ", accuracy_pct, "%"))
```


### Check accuracy of keras model

```{r keras-acc}
# Score on the test set
model %>% evaluate(X_test, Y_test, batch_size = 32)

predictions = character(nrow(test))
for (i in 1:nrow(test)) {
  mel = testMels[[i]]
  prediction = which.max(colMeans(predict_proba(model, mel)))
  prediction = levels(testM.labels)[prediction]
  predictions[i] = prediction
}
testWithPredictions = data.frame(test, predictions)
testWithPredictions
correct_predictions = nrow(filter(testWithPredictions, birdid == predictions))
accuracy_pct = round(correct_predictions / nrow(test) * 100, 2)
print(paste(correct_predictions, "/", nrow(test), "wavs in the test dataset correctly identifed. Accuracy: ", accuracy_pct, "%"))
```

randomForest did better.
