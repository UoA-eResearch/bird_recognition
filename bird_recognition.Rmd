---
title: "Bird Recognition"
output:
  html_document:
    df_print: paged
    toc: yes
  html_notebook:
    toc: yes
    toc_float: yes
---

GitHub repo: https://github.com/UoA-eResearch/bird_recognition

## Load the necessary packages

```{r setup, warning=FALSE}
rm(list=ls(all=TRUE))
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning = FALSE)
knitr::opts_chunk$set(fig.width = 12, fig.height = 8, fig.align = 'center')

library(bioacoustics)
library(tuneR)
library(seewave)
library(dplyr)
library(tools)
library(ranger)
library(randomForest)
library(stringr)
library(keras)
library(ggplot2)
```

## Load the wave files. Separate out the metadata from the filename into columns. 

```{r load}
files = list.files("wav_files_playback", "*.wav", full.names=TRUE)
files_without_extension = basename(file_path_sans_ext(files))
wavs = setNames(
  lapply(
    files,
    read_audio
  ),
  files_without_extension
)
metadata = data.frame(str_split_fixed(files_without_extension, "_", 3))
metadata = cbind(metadata, files_without_extension)
colnames(metadata) = c("birdid", "calltype", "idnumber", "filename")
```

Render some spectrograms
```{r visualise spectro, eval=FALSE, include=FALSE}
oscillo(wavs[[1]])
birds = unique(metadata$birdid)
filtered = filter(metadata, birdid == birds[1])
for (i in 1:nrow(filtered)) {
  audio = wavs[[filtered$filename[i]]]
  spectro(audio, main=filtered$filename[i])
}
```

## Split dataset into train / test since the sample size is small, the validation set won't be used for now. The test dataset will contain one row for each combination of birdid / calltype

```{r split, echo=FALSE}
set.seed(1337)
test_row <- sample(1:3,1)
test_row
test <- metadata %>% 
          group_by(birdid, calltype) %>% 
          filter(row_number()==test_row)
          
train <-  metadata %>% 
          group_by(birdid, calltype) %>% 
          filter(row_number()!=test_row)
```

## Visualise the train/test distribution. Here we have three samples for each call type for each individual bird thus we will train our model on two samples, validate it on the last one. In the end, the model will be evaluated on the whole dataset.
```{r}
metadata %>%
  group_by(birdid,calltype) %>% 
  mutate(isTrain=row_number()!=test_row) %>% 
  ungroup() %>% 
  ggplot(aes(birdid,fill=isTrain)) +
    geom_bar(stat = "count") +
    facet_grid(calltype~.) +
    theme_minimal()
```

```{r rf}
mels = sapply(wavs, melfcc, numcep = 20) # Calculate all MFCCs
trainMels = mels[train$filename] # Select the MFCCs corresponding to the training dataset
testMels = mels[test$filename]
```

Audio recordings have different lengths
```{r audio_len, echo=TRUE}
audio_len_train = sapply(trainMels, dim)
audio_len_test = sapply(testMels,dim)
hist(audio_len_train[1,], breaks = 50)
hist(audio_len_test[1,], breaks = 50)
```

Since the audio lengths are different and most of them fall under 20 timesteps, the first 20 timesteps would be extracted. In addition, the number of MFCC coefficients is 20 so the data would have a nice (20,20) shape.

```{r}
timestepTake <- 20
# Only extract 20 first timesteps
extract20 <- function(matrixI) {
  test <- matrix(0,timestepTake,20)
  dimensionM <- dim(matrixI)
  timestepM <- min(timestepTake,dimensionM[1])
  test[1:timestepM, 1:dimensionM[2]] <- matrixI[1:timestepM, 1:dimensionM[2]]
  test
}

# Only taking the first 20 timesteps othwerwise zero
trainMels_20 <- lapply(trainMels, extract20)
testMels_20 <- lapply(testMels, extract20)
```

```{r echo=FALSE}
# Draw spectrograms
image(trainMels_20[[1]])
image(testMels_20[[10]])
```

```{r}
# Flatten the matrices out
trainMels_20 <- matrix(unlist(trainMels_20), ncol=(20*20), byrow=TRUE)
testMels_20 <- matrix(unlist(testMels_20), ncol=(20*20), byrow=TRUE)

# Normalise
maxMels <- do.call(max,mels) # Calculate the max across the whole list of matrices to scale the predictor values between 0-1
trainMels_20 <- trainMels_20/maxMels
testMels_20 <- testMels_20/maxMels
```


## Using Random-Forest
```{r}
set.seed(1337) 
rf = randomForest(trainMels_20, train$birdid, xtest=testMels_20, ytest=test$birdid, importance = FALSE, proximity = FALSE, replace = TRUE, ntree = 1000, mtry = 20)
rf

round(sum(diag(rf$test$confusion)) / sum(rf$test$confusion[,1:(ncol(rf$test$confusion) -1)]) * 100, 2)
```

Visualise wrong predictions

```{r}
fn <- rf$test$predicted != test$birdid

for (i in 1:length(test$birdid)) {
  if (fn[i]) { # If it is false negative
    par(mfrow=c(3,3))
    image(t(matrix(unlist(testMels_20[i,]),ncol = 20, byrow = TRUE)))
    title(paste0(rf$test$predicted[i],">",test$birdid[i]))
    # Show ground truth bird's spectrograms in train dataset
    groundTBird <- which(train$birdid==test$birdid[i])
    for (id in groundTBird) {
      image(t(matrix(unlist(trainMels_20[id,]),ncol = 20, byrow = TRUE)))
      title(test$birdid[i])
    }
    
    par(mfrow=c(3,3))
    image(t(matrix(unlist(testMels_20[i,]),ncol = 20, byrow = TRUE)))
    title(paste0(rf$test$predicted[i],">",test$birdid[i]))
    # Show falsely predicted bird's spectrograms in train dataset
    predBird <- which(train$birdid==rf$test$predicted[i])
    for (id in predBird) {
      image(t(matrix(unlist(trainMels_20[id,]),ncol = 20, byrow = TRUE)))
      title(rf$test$predicted[i])
    }
  }
}
```

Feature Engineering: what about adding column means for each timestep?
```{r}
# Feature engineering
## Add column means or timestep means
colnames(trainMels_20) <- c(paste0("pix",1:400))
colnames(testMels_20) <- c(paste0("pix",1:400))

addColMeans <- function(matrixI) {
  mcol <- matrix(nrow=nrow(matrixI), ncol=timestepTake)
  for (i in 1:timestepTake) {
    mcol[,i] <- rowMeans(matrixI[,i+20*(0:19)])
  }
  colnames(mcol) <- c(paste0("m",1:20))
  results <- cbind(matrixI, mcol)
}

trainMels_20_M <- addColMeans(trainMels_20)
testMels_20_M <- addColMeans(testMels_20)
trainMels_20_M <- cbind(trainMels_20_M,train$birdid)
testMels_20_M <- cbind(testMels_20_M,test$birdid)

colnames(trainMels_20_M)[ncol(trainMels_20_M)] <- "birdid"
colnames(testMels_20_M)[ncol(testMels_20_M)] <- "birdid"
```

# Train new Random Forest model
```{r}
set.seed(1337)
M_ranger <- ranger(dependent.variable.name = "birdid", data = trainMels_20_M, mtry = 20, classification = TRUE, num.trees = 2000, importance = "impurity")
plot(M_ranger$variable.importance, pch=19, col="#00000030")

t_M <- table(predict(M_ranger,testMels_20_M)$predictions, test$birdid)
t_M
round(sum(diag(t_M)) / sum(t_M) * 100, 2)
```
Adding timestep means doesn't boost the performance.

## Deep learning classification with the R interface to Keras based on MFCC, in particular, a CNN model will be used here.

```{r keras, warning=FALSE}
# Assigning input and output variables
X_train <-  trainMels_20
X_test <-  testMels_20
Y_train <-  to_categorical(as.integer(train$birdid) -1)
Y_test <-  to_categorical(as.integer(test$birdid) - 1)

# Build the sequential model
model = keras_model_sequential()
model %>%
  layer_reshape(input_shape=ncol(X_train),target_shape=c(20,20,1)) %>% 
  layer_conv_2d(64, c(3,3), c(1,1), padding='same') %>%
  layer_activation("relu") %>%
  layer_conv_2d(64, c(3,3), c(1,1), padding='same') %>%
  layer_activation("relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_dropout(0.7) %>% 
  layer_conv_2d(128, c(3,3), c(1,1), padding='same') %>%
  layer_activation("relu") %>%
  layer_conv_2d(128, c(3,3), c(1,1), padding='same') %>%
  layer_activation("relu") %>%
  layer_average_pooling_2d(pool_size = c(2,2)) %>% 
  layer_dropout(0.7) %>% 
  layer_flatten() %>%
  layer_dense(64, activation ='relu') %>% 
  layer_dropout(0.5) %>% 
  layer_dense(64, activation ='relu') %>% 
  layer_dropout(0.5) %>%
  layer_dense(units = ncol(Y_train),  activation='softmax')

# Model compile
model %>% compile(loss = 'categorical_crossentropy',
                 optimizer = "adam",
                 metrics = "categorical_accuracy")


# Add a callback to reduce the learning rate when reaching the plateau
reduce_lr <- callback_reduce_lr_on_plateau(monitor = 'loss', factor = 0.5,
                                           patience = 50, min_lr = 0.0001)

```

```{r}
# Start learning
history = model %>% fit(X_train, Y_train, epochs = 400,
             validation_data = list(X_test, Y_test),
              callbacks = reduce_lr, verbose=1)
```

```{r keras-plot}
plot(history)
```

```{r keras-confusion-matrix}
birdPred <- model %>% predict_classes(X_test)
t_CNN <- table(birdPred,test$birdid)
round(sum(diag(t_CNN)) / sum(t_CNN) * 100, 2)
```

randomForest did better.
