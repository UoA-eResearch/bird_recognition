---
title: "Bird Recognition"
output:
  html_document:
    df_print: paged
    toc: yes
  html_notebook:
    toc: yes
    toc_float: yes
---

GitHub repo: https://github.com/UoA-eResearch/bird_recognition

## Load the necessary packages

```{r setup, warning=FALSE}
rm(list=ls(all=TRUE))
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning = FALSE)
knitr::opts_chunk$set(fig.width = 12, fig.height = 8, fig.align = 'center')

library(bioacoustics)
library(tuneR)
library(seewave)
library(dplyr)
library(tools)
library(ranger)
library(randomForest)
library(stringr)
#library(keras)
library(ggplot2)
library(caret)
```

## Load the wave files. Separate out the metadata from the filename into columns. 

```{r load}
files = list.files("wav_files_playback", "*.wav", full.names=TRUE)
files_without_extension = basename(file_path_sans_ext(files))
wavs = setNames(
  lapply(
    files,
    read_audio
  ),
  files_without_extension
)
metadata = data.frame(str_split_fixed(files_without_extension, "_", 3))
metadata = cbind(metadata, files_without_extension)
colnames(metadata) = c("birdid", "calltype", "idnumber", "filename")
```

Render some spectrograms
```{r visualise spectro, eval=FALSE, include=FALSE}
oscillo(wavs[[1]])
birds = unique(metadata$birdid)
filtered = filter(metadata, birdid == birds[1])
for (i in 1:nrow(filtered)) {
  audio = wavs[[filtered$filename[i]]]
  spectro(audio, main=filtered$filename[i])
}
```

## Split dataset into train / test since the sample size is small, the validation set won't be used for now. The test dataset will contain one row for each combination of birdid / calltype

```{r split, echo=FALSE}
set.seed(1337)
test_row <- sample(1:3,1)
test_row
test <- metadata %>% 
          group_by(birdid, calltype) %>% 
          filter(row_number()==test_row)
          
train <-  metadata %>% 
          group_by(birdid, calltype) %>% 
          filter(row_number()!=test_row)
```

## Visualise the train/test distribution. Here we have three samples for each call type for each individual bird thus we will train our model on two samples, validate it on the last one. In the end, the model will be evaluated on the whole dataset.

```{r}
metadata %>%
  group_by(birdid,calltype) %>% 
  mutate(isTrain=row_number()!=test_row) %>% 
  ungroup() %>% 
  ggplot(aes(birdid,fill=isTrain)) +
    geom_bar(stat = "count") +
    facet_grid(calltype~.) +
    theme_minimal()
```

```{r rf}
mels = sapply(wavs, melfcc, numcep = 20) # Calculate all MFCCs
trainMels = mels[train$filename] # Select the MFCCs corresponding to the training dataset
testMels = mels[test$filename]
```

Audio recordings have different lengths
```{r audio_len, echo=TRUE}
audio_len_train = sapply(trainMels, dim)
audio_len_test = sapply(testMels,dim)
hist(audio_len_train[1,], breaks = 50)
hist(audio_len_test[1,], breaks = 50)
```

Since the audio lengths are different and most of them fall under 20 timesteps, the first 20 timesteps would be extracted. In addition, the number of MFCC coefficients is 20 so the data would have a nice (20,20) shape.

```{r}
timestepTake <- 20
# Only extract 20 first timesteps
extract20 <- function(matrixI) {
  test <- matrix(0,timestepTake,20)
  dimensionM <- dim(matrixI)
  timestepM <- min(timestepTake,dimensionM[1])
  test[1:timestepM, 1:dimensionM[2]] <- matrixI[1:timestepM, 1:dimensionM[2]]
  test
}

# Only taking the first 20 timesteps othwerwise zero
trainMels_20 <- lapply(trainMels, extract20)
testMels_20 <- lapply(testMels, extract20)
```

```{r echo=FALSE}
# Draw spectrograms
image(trainMels_20[[1]])
image(testMels_20[[10]])
```

```{r}
# Flatten the matrices out
trainMels_20 <- matrix(unlist(trainMels_20), ncol=(20*20), byrow=TRUE)
testMels_20 <- matrix(unlist(testMels_20), ncol=(20*20), byrow=TRUE)

# Normalise
maxMels <- do.call(max,mels) # Calculate the max across the whole list of matrices to scale the predictor values between 0-1
trainMels_20 <- trainMels_20/maxMels
testMels_20 <- testMels_20/maxMels
```


## Using Random-Forest from `randomForest` package
```{r}
set.seed(138) 
rf = randomForest(trainMels_20, train$birdid, xtest=testMels_20, ytest=test$birdid, importance = FALSE, proximity = FALSE, replace = TRUE, ntree = 1000, mtry = 20)
rf

round(sum(diag(rf$test$confusion)) / sum(rf$test$confusion[,1:(ncol(rf$test$confusion) -1)]) * 100, 2)
```

Visualise wrong predictions

```{r}
fn <- rf$test$predicted != test$birdid

for (i in 1:length(test$birdid)) {
  if (fn[i]) { # If it is false negative
    par(mfrow=c(3,3))
    image(t(matrix(unlist(testMels_20[i,]),ncol = 20, byrow = TRUE)))
    title(paste0(rf$test$predicted[i],">",test$birdid[i]))
    # Show ground truth bird's spectrograms in train dataset
    groundTBird <- which(train$birdid==test$birdid[i])
    for (id in groundTBird) {
      image(t(matrix(unlist(trainMels_20[id,]),ncol = 20, byrow = TRUE)))
      title(test$birdid[i])
    }
    
    par(mfrow=c(3,3))
    image(t(matrix(unlist(testMels_20[i,]),ncol = 20, byrow = TRUE)))
    title(paste0(rf$test$predicted[i],">",test$birdid[i]))
    # Show falsely predicted bird's spectrograms in train dataset
    predBird <- which(train$birdid==rf$test$predicted[i])
    for (id in predBird) {
      image(t(matrix(unlist(trainMels_20[id,]),ncol = 20, byrow = TRUE)))
      title(rf$test$predicted[i])
    }
  }
}
```

Feature Engineering: what about adding column means for each timestep?
```{r}
# Feature engineering
## Add column means or timestep means
colnames(trainMels_20) <- c(paste0("pix",1:400))
colnames(testMels_20) <- c(paste0("pix",1:400))

addColMeans <- function(matrixI) {
  mcol <- matrix(nrow=nrow(matrixI), ncol=timestepTake)
  for (i in 1:timestepTake) {
    mcol[,i] <- rowMeans(matrixI[,i+20*(0:19)])
  }
  colnames(mcol) <- c(paste0("m",1:20))
  results <- cbind(matrixI, mcol)
}

trainMels_20_M <- addColMeans(trainMels_20)
testMels_20_M <- addColMeans(testMels_20)
trainMels_20_M <- cbind(trainMels_20_M,train$birdid)
testMels_20_M <- cbind(testMels_20_M,test$birdid)

colnames(trainMels_20_M)[ncol(trainMels_20_M)] <- "birdid"
colnames(testMels_20_M)[ncol(testMels_20_M)] <- "birdid"


trainMels_20 <- cbind(trainMels_20,train$birdid)
testMels_20 <- cbind(testMels_20,test$birdid)
colnames(trainMels_20)[ncol(trainMels_20)] <- "birdid"
colnames(testMels_20)[ncol(testMels_20)] <- "birdid"
```

# Train new Random Forest model. Use `ranger` package here because it has better performance with bigger dataset and it is compatible with `caret` for grid-search later
```{r}
#set.seed(138)
M_ranger <- ranger(dependent.variable.name = "birdid", data = trainMels_20_M, mtry = 20, classification = TRUE, num.trees = 2000, importance = "impurity", splitrule = "extratrees", num.random.splits=1)
plot(M_ranger$variable.importance, pch=19, col="#00000030")

M_ranger
t_M <- table(predict(M_ranger,testMels_20_M)$predictions, test$birdid)
t_M
round(sum(diag(t_M)) / sum(t_M) * 100, 2)
```

Adding timestep means doesn't boost the performance.

# Have to comment on the variable importance plot.

#TODO: Grid Search

```{r}
set.seed(138)

index <- train %>%
  add_rownames() %>% 
  group_by(birdid, calltype) %>% 
  mutate(rownum=row_number()) %>%
  group_by(rownum) %>% 
  select(rowname) %>% 
  group_split()

index <- list(as.integer(index[[1]]$rowname), as.integer(index[[2]]$rowname))

tgrid <- expand.grid(
 .mtry = c(15,20),
 .splitrule = c("extratrees","gini"),
 .min.node.size = 1
)

rangerFit1 <- train(factor(birdid)~., data = trainMels_20,
                 method = "ranger",
                 trControl = trainControl(index=index),
                 verbose = FALSE,
                 classification = TRUE,
                 num.trees = 2000,
                 tuneGrid= tgrid
                 )
rangerFit1

```

```{r}
t_rangerFit1 <- table(predict(rangerFit1, testMels_20),test$birdid)
t_rangerFit1
round(sum(diag(t_rangerFit1)) / sum(t_rangerFit1) * 100, 2)
```
